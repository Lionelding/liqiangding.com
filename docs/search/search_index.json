{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to the Story of My Kingdom! \u00b6 img { border: 1px solid #ddd; border-radius: 4px; padding: 5px; width: 640px; float: center } My name is Liqiang Ding. I am a cat-lover, a big fun of sci-fi movies and classical music. This blog is a place to share my discoveries from life and work. I wish you enjoy reading it. :)","title":"Home"},{"location":"index.html#welcome-to-the-story-of-my-kingdom","text":"img { border: 1px solid #ddd; border-radius: 4px; padding: 5px; width: 640px; float: center } My name is Liqiang Ding. I am a cat-lover, a big fun of sci-fi movies and classical music. This blog is a place to share my discoveries from life and work. I wish you enjoy reading it. :)","title":"Welcome to the Story of My Kingdom!"},{"location":"about.html","text":"About Myself \u00b6 Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Artificial Intelligence? Computer Vision? Natural language Processing? \u00b6 Artificial Intelligence never fails to appeal to me. Just like Doraemon to Nobita Nobi , I have been dreaming of having a computer friend since I was a kid. It has a bunch of fancy inventions from the 22 nd century in his four dimension pocket, joins me on the adventure exploring this world, and most importantly, teaches by honest words and actions instead of banalities. For years, I scratched numerous drafts about how it would look like, imagined the fancy capabilities it might have, and even came up with scenarios where it could come to realities without scaring my parents. Well, most of them is lost in time, but the fantasy for building such a powerful program still sticks to my mind. Finished the elementary school and high school in China, I was fortunate to came aboard to Canada to continue my study at McGill University, majoring in eletrical engineering. Studying at McGill really broadened my horizons, and it was the real starting point for me to get to know programming algorithms, electrical circuits, information theory and a lot of cool stuff. Being exposure to this massive amount of new knowledge is an exciting yet challenging journey, and no need for mentioning how many nights spent in the Schulich library. However, there was always one question confusing me: What do I want to do with these great pieces of knowledge? Trying to find this answer, I took a few internships across different industries, with various technical focuses. I witnessed how teams across the world leveraged their own experties, contributing to making a great product that faciliated millions of people. I was also amazed to see that people were willing to spend days in improving browsers just to render contents with 1 second faster. On one side, all of these experiences pushed me to go further with my study, and opened completely new worlds. On the other side, they also deepened my question. Time is limited, decisions need to be made. In the last year of my bachelor study, one of my friends mentioned me a course of computer vision that he was about to take. For curiosity, I clicked the course website in the evening, and was greatly surprised of the cool things that it can do. For the first time I know, computer algorithm is not only used to sort an array or to design the shortest path for a busy postman. Instead, it can be so connected to the daily pictures we take, to recognize a poker card, to restore an old image, and even to stabilize poor-taken videos from amateurs. After a few assignments, I was really fascinated by these algorithms behind it.","title":"About Myself"},{"location":"about.html#about-myself","text":"Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"About Myself"},{"location":"about.html#artificial-intelligence-computer-vision-natural-language-processing","text":"Artificial Intelligence never fails to appeal to me. Just like Doraemon to Nobita Nobi , I have been dreaming of having a computer friend since I was a kid. It has a bunch of fancy inventions from the 22 nd century in his four dimension pocket, joins me on the adventure exploring this world, and most importantly, teaches by honest words and actions instead of banalities. For years, I scratched numerous drafts about how it would look like, imagined the fancy capabilities it might have, and even came up with scenarios where it could come to realities without scaring my parents. Well, most of them is lost in time, but the fantasy for building such a powerful program still sticks to my mind. Finished the elementary school and high school in China, I was fortunate to came aboard to Canada to continue my study at McGill University, majoring in eletrical engineering. Studying at McGill really broadened my horizons, and it was the real starting point for me to get to know programming algorithms, electrical circuits, information theory and a lot of cool stuff. Being exposure to this massive amount of new knowledge is an exciting yet challenging journey, and no need for mentioning how many nights spent in the Schulich library. However, there was always one question confusing me: What do I want to do with these great pieces of knowledge? Trying to find this answer, I took a few internships across different industries, with various technical focuses. I witnessed how teams across the world leveraged their own experties, contributing to making a great product that faciliated millions of people. I was also amazed to see that people were willing to spend days in improving browsers just to render contents with 1 second faster. On one side, all of these experiences pushed me to go further with my study, and opened completely new worlds. On the other side, they also deepened my question. Time is limited, decisions need to be made. In the last year of my bachelor study, one of my friends mentioned me a course of computer vision that he was about to take. For curiosity, I clicked the course website in the evening, and was greatly surprised of the cool things that it can do. For the first time I know, computer algorithm is not only used to sort an array or to design the shortest path for a busy postman. Instead, it can be so connected to the daily pictures we take, to recognize a poker card, to restore an old image, and even to stabilize poor-taken videos from amateurs. After a few assignments, I was really fascinated by these algorithms behind it.","title":"Artificial Intelligence? Computer Vision? Natural language Processing?"},{"location":"backup.html","text":"","title":"Backup"},{"location":"blogs.html","text":"Hello World \u00b6 Gradient Class Activation Map (Grad-CAM) Summary \u00b6 The following note demonstrates the logic procedure of how a GradCam is computed. For ... Blog Title 2 \u00b6 Blog Title 3 \u00b6 Blog Title 4 \u00b6 Blog Title 5 \u00b6","title":"Technical Blogs"},{"location":"blogs.html#hello-world","text":"","title":"Hello World"},{"location":"blogs.html#gradient-class-activation-map-grad-cam-summary","text":"The following note demonstrates the logic procedure of how a GradCam is computed. For ...","title":"Gradient Class Activation Map (Grad-CAM) Summary"},{"location":"blogs.html#blog-title-2","text":"","title":"Blog Title 2"},{"location":"blogs.html#blog-title-3","text":"","title":"Blog Title 3"},{"location":"blogs.html#blog-title-4","text":"","title":"Blog Title 4"},{"location":"blogs.html#blog-title-5","text":"","title":"Blog Title 5"},{"location":"gallery.html","text":"","title":"Time Capsule Studio"},{"location":"projects.html","text":"Coming...","title":"Projects"},{"location":"pub.html","text":"My Research Interests \u00b6 Google scholar Papers \u00b6 Artificial Intelligence for Real-Time Multiple Polyp Detection with Identification, Tracking, and Optical Biopsy During Colonoscopy \u00b6 Gastroenterology, 2019 Task Adaptive Metric Space for Medium-Shot Medical Image Classification \u00b6 Medical Image Computing and Computer Assisted Interventions (MICCAI) 2019 Deep-learning-based multiple object tracking in traffic surveillance video \u00b6 Master Thesis, 2018 Generation of spatial-temporal panoramas with a single moving camera \u00b6 13 th Conference on Computer and Robot Vision (CRV), 2016 poster Patents \u00b6 Apparatus and method for detecting, classifying and tracking road users on frames of video data \u00b6 Patent in US and CA","title":"Research & Publication"},{"location":"pub.html#my-research-interests","text":"Google scholar","title":"My Research Interests"},{"location":"pub.html#papers","text":"","title":"Papers"},{"location":"pub.html#artificial-intelligence-for-real-time-multiple-polyp-detection-with-identification-tracking-and-optical-biopsy-during-colonoscopy","text":"Gastroenterology, 2019","title":"Artificial Intelligence for Real-Time Multiple Polyp Detection with Identification, Tracking, and Optical Biopsy During Colonoscopy"},{"location":"pub.html#task-adaptive-metric-space-for-medium-shot-medical-image-classification","text":"Medical Image Computing and Computer Assisted Interventions (MICCAI) 2019","title":"Task Adaptive Metric Space for Medium-Shot Medical Image Classification"},{"location":"pub.html#deep-learning-based-multiple-object-tracking-in-traffic-surveillance-video","text":"Master Thesis, 2018","title":"Deep-learning-based multiple object tracking in traffic surveillance video"},{"location":"pub.html#generation-of-spatial-temporal-panoramas-with-a-single-moving-camera","text":"13 th Conference on Computer and Robot Vision (CRV), 2016 poster","title":"Generation of spatial-temporal panoramas with a single moving camera"},{"location":"pub.html#patents","text":"","title":"Patents"},{"location":"pub.html#apparatus-and-method-for-detecting-classifying-and-tracking-road-users-on-frames-of-video-data","text":"Patent in US and CA","title":"Apparatus and method for detecting, classifying and tracking road users on frames of video data"},{"location":"read.html","text":"","title":"Grande Biblioth\u00e8que"},{"location":"MyBlogs/GradCam.html","text":"Gradient Class Activation Map (Grad-CAM) Summary \u00b6 The following note demonstrates the logic procedure of how a GradCam is computed. For details, please see: Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization Assumption \u00b6 Class Activation Mapping \u00b6 y^{c} = \\sum\\limits_{k} w^k_c \\frac{1}{Z} \\sum\\limits_{i} \\sum\\limits_{j} A^k_{ij} The penultimate layer produces K K activation map A^K A^K with width u u and height v v . The feature goes through \\frac{1}{Z} \\sum\\limits_{i} \\sum\\limits_{j} \\frac{1}{Z} \\sum\\limits_{i} \\sum\\limits_{j} , which is called global averaged pooled , and then linearly transforemd to y^{c} y^{c} for each class c c . Procedure \u00b6 1. Choose the penultimate layer. \u00b6 This is the layer where we want to visualize the activation map. The reason why it is called the penultimate layer is because the last layer of a model is usually the layer computing class-specific loss (i.e. Sigmoid loss, softmax loss, etc). The penultimate layer is a layer, which is before the last layer, that we want to compute the loss respect to. 2. Compute the class-specific loss (i.e. loss of y^{c} y^{c} ) on the last layer of the model. \u00b6 3. Compute the gradients of y^c y^c respect to the penultimate layer's activation map A^K A^K . \u00b6 \\alpha^c_k = \\frac{1}{Z} \\sum\\limits_{i} \\sum\\limits_{j} \\frac{\\partial y^c}{\\partial A^k_{ij}} The dimension of the gradients is then reduced from (batch_size, u, v, channel) to (channel) by averaging the values in the first three axises. In the paper, this dimension reduction is called global-average-pooling . This result denoted as \\alpha^c_k \\alpha^c_k represents a partial linearization of the penultimate layer to the loss, which captures the importance of the activation A^k A^k for a target c c . 4. Elemently-wise multpile the the gradient with the Activation map. \u00b6 5. Remove any negative results by applying the Relu function over the result. \u00b6 Only interested in the positive influence on the class of interest. (i.e. Pixels whose intensity should increase in order to increase y^{c} y^{c} ) L^c_{Grad-CAM} = Relu(\\sum\\limits_{k} \\alpha^c_k A^k)","title":"Gradient Class Activation Map (Grad-CAM) Summary"},{"location":"MyBlogs/GradCam.html#gradient-class-activation-map-grad-cam-summary","text":"The following note demonstrates the logic procedure of how a GradCam is computed. For details, please see: Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization","title":"Gradient Class Activation Map (Grad-CAM) Summary"},{"location":"MyBlogs/GradCam.html#assumption","text":"","title":"Assumption"},{"location":"MyBlogs/GradCam.html#class-activation-mapping","text":"y^{c} = \\sum\\limits_{k} w^k_c \\frac{1}{Z} \\sum\\limits_{i} \\sum\\limits_{j} A^k_{ij} The penultimate layer produces K K activation map A^K A^K with width u u and height v v . The feature goes through \\frac{1}{Z} \\sum\\limits_{i} \\sum\\limits_{j} \\frac{1}{Z} \\sum\\limits_{i} \\sum\\limits_{j} , which is called global averaged pooled , and then linearly transforemd to y^{c} y^{c} for each class c c .","title":"Class Activation Mapping"},{"location":"MyBlogs/GradCam.html#procedure","text":"","title":"Procedure"},{"location":"MyBlogs/GradCam.html#1-choose-the-penultimate-layer","text":"This is the layer where we want to visualize the activation map. The reason why it is called the penultimate layer is because the last layer of a model is usually the layer computing class-specific loss (i.e. Sigmoid loss, softmax loss, etc). The penultimate layer is a layer, which is before the last layer, that we want to compute the loss respect to.","title":"1. Choose the penultimate layer."},{"location":"MyBlogs/GradCam.html#2-compute-the-class-specific-loss-ie-loss-of-ycyc-on-the-last-layer-of-the-model","text":"","title":"2. Compute the class-specific loss (i.e. loss of y^{c}y^{c}) on the last layer of the model."},{"location":"MyBlogs/GradCam.html#3-compute-the-gradients-of-ycyc-respect-to-the-penultimate-layers-activation-map-akak","text":"\\alpha^c_k = \\frac{1}{Z} \\sum\\limits_{i} \\sum\\limits_{j} \\frac{\\partial y^c}{\\partial A^k_{ij}} The dimension of the gradients is then reduced from (batch_size, u, v, channel) to (channel) by averaging the values in the first three axises. In the paper, this dimension reduction is called global-average-pooling . This result denoted as \\alpha^c_k \\alpha^c_k represents a partial linearization of the penultimate layer to the loss, which captures the importance of the activation A^k A^k for a target c c .","title":"3. Compute the gradients of y^cy^c respect to the penultimate layer's activation map A^KA^K."},{"location":"MyBlogs/GradCam.html#4-elemently-wise-multpile-the-the-gradient-with-the-activation-map","text":"","title":"4. Elemently-wise multpile the the gradient with the Activation map."},{"location":"MyBlogs/GradCam.html#5-remove-any-negative-results-by-applying-the-relu-function-over-the-result","text":"Only interested in the positive influence on the class of interest. (i.e. Pixels whose intensity should increase in order to increase y^{c} y^{c} ) L^c_{Grad-CAM} = Relu(\\sum\\limits_{k} \\alpha^c_k A^k)","title":"5. Remove any negative results by applying the Relu function over the result."}]}